# ðŸš€ Quick Start

## 0. Environment Setup

```bash
# Create a Python 3.11 environment named dsrsql
conda create -n dsrsql python=3.11 -y

# Activate the environment
conda activate dsrsql

# Enter the directory
cd DSR_Lite

# Install dependencies
pip install -r requirements.txt
```

## 1. Other Preparations

### 1.1. Dataset Download

Please download the [Spider2.0-Lite folder](https://github.com/xlang-ai/Spider2/tree/main/spider2-lite) into the `DSR_Lite` directory.
Additionally, download the [Sqlite local database](https://github.com/xlang-ai/Spider2/tree/main/spider2-lite#-quickstart) and place it in `spider2-lite\resource\databases`.

**The directory structure is as follows:**

```text
DSR_Lite
â””â”€â”€ spider2-lite
    â”œâ”€â”€ evaluation_suite
    â””â”€â”€ resource
        â””â”€â”€ databases
            â”œâ”€â”€ bigquery
            â”œâ”€â”€ snowflake
            â”œâ”€â”€ sqlite
            â””â”€â”€ spider2-localdb #This is the downloaded database folder.
                â”œâ”€â”€ AdventureWorks.sqlite
                â”œâ”€â”€ Airlines.sqlite
                â”œâ”€â”€ bank_sales_trading.sqlite
                â””â”€â”€ ...
main_lite.py
```

### 1.2. Database Credential Acquisition

1.  Please follow the official requirements to obtain the account and password for the corresponding online databases.
2.  Place the corresponding key files in the following paths:
    *   `spider2-lite/evaluation_suite/bigquery_credential.json`
    *   `spider2-lite/evaluation_suite/snowflake_credential.json`
3.  Finally, please configure all database mapping information in [DB.json](../DSR_Lite/utils/DBsetup/DB.json).

### 1.3. LLM Configuration

1.  Please configure the corresponding key, URL, and other information in [LLM_config.json](../DSR_Lite/LLM/LLM_config.json).
2.  Similarly, you can configure your own LLM usage functions according to the [requirements](../DSR_Lite/LLM/LM_func_template.md).
3.  Then, please set the main LLM used for SQL generation in the [Prompt.py](../DSR_Lite/utils/Prompt.py) file. We recommend using DeepSeek or other closed-source models (due to Snowflake syntax constraints).

## 2. Scripts

### Schema and Knowledge Refinement

> **Note**: Please check the sh files to configure the corresponding LLM.

```bash
bash script/preprocess.sh
bash script/Knowledge_Compression.sh
```

For preprocessing, you can directly use the [file](https://drive.google.com/drive/folders/1gHTF00E4f0uK2hEEOOV0kPuUpDr3sjfP?usp=drive_link) (2025-10) generated by us, but you need to place the corresponding files into the appropriate folders, as shown below:

```text
sqlite
â””â”€â”€ AdventureWorks
    â””â”€â”€ AdventureWorks_M-Schema.json  # Move the corresponding JSON file into the database folder of the same name
```

### Adaptive Schema Selection

> **Note**: Please check the sh files to configure the corresponding LLM.

```bash
bash script/Schema_Selection.sh
```

### Generation-State Evolution

**Run command:**

```bash
python main_lite.py --input_path DSR_Lite/spider2-lite/spider2-lite_SL.json
```

> **Note**: If the workflow is interrupted and you wish to restart, please use the following command, which allows execution to resume from where it stopped:

```bash
python main_lite.py --input_path DSR_Lite/spider2-lite/spider2-lite_SL.json --data_sub_dir DSR_Lite/Result_12081549
```

## 3. Evaluation
TBD

## Other

- We have provided the [input files](../DSR_Lite/data) for the Generation-State Evolution step to facilitate reproduction.
- We have displayed the [full log files](../DSR_Lite/Result_12081549) of DSR-SQL running on some examples. You can check how DSR-SQL performs the " Explore" step in [sf_bq270](../DSR_Lite/Result_12081549/log/sf_bq270_1/main_sf_bq270_1.log).
- Due to the offline status of the DeepSeek-R1/V3 series models and changes in online databases, the results may differ slightly!